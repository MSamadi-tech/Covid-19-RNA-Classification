{"cells":[{"cell_type":"code","execution_count":null,"id":"a90c5602-6a98-4b2c-88a1-7e43cd06c3f5","metadata":{"id":"a90c5602-6a98-4b2c-88a1-7e43cd06c3f5"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, MaxPooling1D, Flatten, Dropout, BatchNormalization, Conv1D, Bidirectional,ReLU\n","import pandas as pd\n","import numpy as np\n","import gc\n","import random"]},{"cell_type":"code","execution_count":null,"id":"4f929600-2604-42f8-a6cc-3e18c25940b9","metadata":{"id":"4f929600-2604-42f8-a6cc-3e18c25940b9"},"outputs":[],"source":["def clear_variable(var_list):\n","    for var in var_list:\n","        globals().pop(var, None)\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"id":"276a7da4-0a75-449c-8a5d-60424d2c06fa","metadata":{"id":"276a7da4-0a75-449c-8a5d-60424d2c06fa"},"outputs":[],"source":["subset_list = []\n","\n","for i in range(20):\n","  subset_list.append(f'rnn_data_subset{i+1}.csv')"]},{"cell_type":"code","execution_count":null,"id":"cc81147b-e75d-4117-a3fe-f689ac70e0b1","metadata":{"id":"cc81147b-e75d-4117-a3fe-f689ac70e0b1"},"outputs":[],"source":["X_train_list, X_test_list, X_val_list = [], [], []\n","y_train_list, y_test_list, y_val_list = [], [], []\n","\n","for i in range(len(subset_list)):\n","  file_path = 'rnn_data_subset_{index}.csv'.format(index=i+1)\n","  read_data = pd.read_csv(file_path)\n","\n","  data_features = np.array(read_data.drop('class', axis=1))\n","  data_labels = read_data['class']\n","  clear_variable('read_data')\n","\n","  X_train_list.append(data_features[:700])\n","  X_val_list.append(data_features[700:800])\n","  X_test_list.append(data_features[800:])\n","  clear_variable('data_features')\n","\n","  y_train_list.append(data_labels[:700])\n","  y_val_list.append(data_labels[700:800])\n","  y_test_list.append(data_labels[800:])\n","  clear_variable('data_labels')\n","\n","X_train = np.concatenate(X_train_list, axis=0)\n","clear_variable('X_train_list')\n","\n","X_test = np.concatenate(X_test_list, axis=0)\n","clear_variable('X_test_list')\n","\n","X_val = np.concatenate(X_val_list, axis=0)\n","clear_variable('X_val_list')\n","\n","y_train = np.concatenate(y_train_list, axis=0)\n","clear_variable('y_train_list')\n","\n","y_test = np.concatenate(y_test_list, axis=0)\n","clear_variable('y_test_list')\n","\n","y_val = np.concatenate(y_val_list, axis=0)\n","clear_variable('y_val_list')"]},{"cell_type":"code","execution_count":null,"id":"b46ea5f6-d301-415d-afa3-d25c8201b42a","metadata":{"id":"b46ea5f6-d301-415d-afa3-d25c8201b42a"},"outputs":[],"source":["# Adjust labels\n","y_train = y_train - 1\n","y_val = y_val - 1\n","y_test = y_test - 1"]},{"cell_type":"markdown","id":"a467fc43-9afc-4ab5-9816-915bfb353a80","metadata":{"id":"a467fc43-9afc-4ab5-9816-915bfb353a80"},"source":["## **Deep Learning Modela**"]},{"cell_type":"code","execution_count":null,"id":"67adc211-f9f1-4edb-97a1-e560ba66ad48","metadata":{"id":"67adc211-f9f1-4edb-97a1-e560ba66ad48"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.utils import Sequence\n","\n","class DataGenerator(Sequence):\n","    def __init__(self, X, y, batch_size):\n","        self.X = X\n","        self.y = y\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.X) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","        batch_x = self.X[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        return np.array(batch_x), np.array(batch_y)\n"]},{"cell_type":"code","execution_count":null,"id":"dc0ef7c4-71bb-4f27-9acf-512ac42836e4","metadata":{"id":"dc0ef7c4-71bb-4f27-9acf-512ac42836e4"},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","import numpy as np\n","\n","class CustomDataGenerator(Sequence):\n","    def __init__(self, data, labels, batch_size, shuffle=True):\n","        self.data = data\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.indexes = np.arange(len(self.data))  # Create indexes for data shuffling\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        # Get the batch indexes\n","        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","        batch_data = self.data[batch_indexes]\n","        batch_labels = self.labels[batch_indexes]\n","\n","        return batch_data, batch_labels\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n"]},{"cell_type":"code","execution_count":null,"id":"7a785c51-8137-46c1-b924-06196faf8698","metadata":{"id":"7a785c51-8137-46c1-b924-06196faf8698"},"outputs":[],"source":["# Define constants\n","vocab_size = 65\n","embedding_dim = 16\n","num_classes = 8\n","input_shape = (30000, 1)"]},{"cell_type":"code","execution_count":null,"id":"899b67e6-0c33-49d4-bb78-4e6d7178d5a0","metadata":{"id":"899b67e6-0c33-49d4-bb78-4e6d7178d5a0"},"outputs":[],"source":["from tensorflow.keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch, lr):\n","    if epoch < 5:\n","        return lr\n","    else:\n","        return float(lr * tf.math.exp(-0.1).numpy())\n","\n","lr_scheduler = LearningRateScheduler(scheduler)\n"]},{"cell_type":"markdown","id":"5ee18659-2cda-47bf-b201-01356a6e45cc","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"5ee18659-2cda-47bf-b201-01356a6e45cc"},"source":["### **CNN-LSTM Model**"]},{"cell_type":"code","execution_count":null,"id":"4499754e-5a9e-43d0-93b1-c4969b236983","metadata":{"id":"4499754e-5a9e-43d0-93b1-c4969b236983"},"outputs":[],"source":["# Build the model\n","model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_shape[0], input_shape=(30000,)),\n","\n","    Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Bidirectional(LSTM(units=64, activation='tanh')),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    # Fully Connected Layers\n","    Dense(units=256, activation='relu'),\n","    Dropout(0.5),\n","\n","    # Output Layer\n","    Dense(units=num_classes, activation='softmax')\n","])\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n","\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Model summary\n","model.summary()\n"]},{"cell_type":"markdown","id":"42f61d5a-95ec-4f7b-a199-f627d2a5c0fb","metadata":{"id":"42f61d5a-95ec-4f7b-a199-f627d2a5c0fb"},"source":["### **CNN Model**"]},{"cell_type":"code","execution_count":null,"id":"365ffc8f-62ff-4060-a9a1-b2c92caa202d","metadata":{"id":"365ffc8f-62ff-4060-a9a1-b2c92caa202d"},"outputs":[],"source":["# Build the model\n","model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_shape[0], input_shape=(30000,)),\n","\n","    Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n","    MaxPooling1D(pool_size=4),\n","    Dropout(0.3),\n","\n","    Flatten(),\n","\n","    # Fully Connected Layers\n","    Dense(units=256, activation='relu'),\n","    Dropout(0.5),\n","\n","    # Output Layer\n","    Dense(units=num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Model summary\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"id":"e0439105-ce47-4d3d-a62a-a939a986d143","metadata":{"id":"e0439105-ce47-4d3d-a62a-a939a986d143"},"outputs":[],"source":["# Assuming data is split into train, val, test sets\n","train_gen = DataGenerator(X_train, y_train, batch_size=32)\n","val_gen = DataGenerator(X_val, y_val, batch_size=32)\n","\n","# Now train the model\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=25,\n","    callbacks=[lr_scheduler],\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"id":"ad9dcb73-aa5d-4ec0-b111-08b860338303","metadata":{"id":"ad9dcb73-aa5d-4ec0-b111-08b860338303"},"outputs":[],"source":["test_gen = DataGenerator(X_test, y_test, batch_size=64)\n","test_loss, test_acc = model.evaluate(test_gen)\n","\n","#print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_acc}\")"]},{"cell_type":"code","execution_count":null,"id":"5b41f840-2edd-42d6-92d1-568eb58cfb1d","metadata":{"id":"5b41f840-2edd-42d6-92d1-568eb58cfb1d"},"outputs":[],"source":["# Save the related model\n","model.save('models/3-mer_cnn.keras')\n","model.save('models/3-mer_cnn_lstm.keras')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}