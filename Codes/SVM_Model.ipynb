{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTQMh7A0VAMiR0hntgftHt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Model**"
      ],
      "metadata": {
        "id": "Vbw-qrwqF6J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import gc\n",
        "from google.colab import drive\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "YP5WkniOfPFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "udCp5HEnfRw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_variable(var_list):\n",
        "    for var in var_list:\n",
        "        globals().pop(var, None)  # Remove from global scope\n",
        "    gc.collect() # Run garbage collection"
      ],
      "metadata": {
        "id": "T1eXRPpcfSPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []\n",
        "\n",
        "for i in range(20):\n",
        "  file_list.append(f'Shuffled_Subset{i}.h5')"
      ],
      "metadata": {
        "id": "V_OtoswZfT1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved IncrementalPCA object\n",
        "loaded_pca_32 = joblib.load('/content/drive/MyDrive/ML_Models/Inc_PCA_n32_Covid.pkl')\n",
        "loaded_pca_64 = joblib.load('/content/drive/MyDrive/ML_Models/Inc_PCA_n64_Covid.pkl')\n",
        "loaded_pca_128 = joblib.load('/content/drive/MyDrive/ML_Models/Inc_PCA_n128_Covid.pkl')\n",
        "loaded_pca_256 = joblib.load('/content/drive/MyDrive/ML_Models/Inc_PCA_n256_Covid.pkl')"
      ],
      "metadata": {
        "id": "CcgEWR3JgfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Gridsearch**"
      ],
      "metadata": {
        "id": "usasKY77gqJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA 32**"
      ],
      "metadata": {
        "id": "mLu1bnvygq5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list, X_test_list = [], []\n",
        "y_train_list, y_test_list = [], []\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_path = '/content/drive/MyDrive/ML_DL_Datasets/DNA_Datasets/Shuffled_Datasets/Covid_Shuffled_Balanced/Shuffled_Subset{file_counter}.h5'.format(file_counter = i+1)\n",
        "  read_data = pd.read_hdf(file_path) # Read the current dataset\n",
        "\n",
        "  data_reshaped = np.array(read_data.drop('Class', axis=1))\n",
        "  data_labels = read_data['Class']\n",
        "  clear_variable('read_data')\n",
        "\n",
        "  X_train_list.append(data_reshaped[:800])\n",
        "  X_test_list.append(data_reshaped[800:])\n",
        "  clear_variable('data_reshaped')\n",
        "\n",
        "  y_train_list.append(data_labels[:800])\n",
        "  y_test_list.append(data_labels[800:])\n",
        "  clear_variable('data_labels')\n",
        "\n",
        "X_train = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable('X_train_list')\n",
        "\n",
        "X_test = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable('X_test_list')\n",
        "\n",
        "y_train = np.concatenate(y_train_list, axis=0)\n",
        "clear_variable('y_train_list')\n",
        "\n",
        "y_test = np.concatenate(y_test_list, axis=0)\n",
        "clear_variable('y_test_list')"
      ],
      "metadata": {
        "id": "Bd79Vd21g3Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = []\n",
        "X_test_list = []\n",
        "batch_size = 1000\n",
        "\n",
        "for start in range(0, len(X_train), batch_size):\n",
        "  X_train_batch = X_train[start : start + batch_size]\n",
        "  X_train_list.append(loaded_pca_32.transform(X_train_batch)) # Transform the X_train with PCA\n",
        "\n",
        "X_train_pca = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable(['X_train_list', 'X_train'])\n",
        "\n",
        "for start in range(0, len(X_test), batch_size):\n",
        "  X_test_batch = X_test[start : start + batch_size]\n",
        "  X_test_list.append(loaded_pca_32.transform(X_test_batch)) # Transform the X_test with PCA\n",
        "\n",
        "X_test_pca = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable(['X_test_list', 'X_test'])"
      ],
      "metadata": {
        "id": "cR4m9-qwgiRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [800,1200,1800,2500,5000,7500,10000],\n",
        "              'gamma':[0.3,0.1,0.07,0.03,0.01,0.003]}\n",
        "\n",
        "grid = GridSearchCV(SVC(),\n",
        "                    param_grid,\n",
        "                    cv=5,\n",
        "                    verbose=3)\n",
        "\n",
        "grid.fit(X_train_pca, y_train)"
      ],
      "metadata": {
        "id": "4AHfNQl-g8lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = grid.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Best parameters: {x}'.format(x=grid.best_params_))\n",
        "print(\"Test Set Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "yvenI7-ug8i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and format the classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "class_report_df = class_report_df.round(4)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_df.to_string())"
      ],
      "metadata": {
        "id": "TGhNMMSDhDoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA 64**"
      ],
      "metadata": {
        "id": "xOoslLnJDx46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list, X_test_list = [], []\n",
        "y_train_list, y_test_list = [], []\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_path = '/content/drive/MyDrive/ML_DL_Datasets/DNA_Datasets/Shuffled_Datasets/Covid_Shuffled_Balanced/Shuffled_Subset{file_counter}.h5'.format(file_counter = i+1)\n",
        "  read_data = pd.read_hdf(file_path) # Read the current dataset\n",
        "\n",
        "  data_reshaped = np.array(read_data.drop('Class', axis=1))\n",
        "  data_labels = read_data['Class']\n",
        "  clear_variable('read_data')\n",
        "\n",
        "  X_train_list.append(data_reshaped[:800])\n",
        "  X_test_list.append(data_reshaped[800:])\n",
        "  clear_variable('data_reshaped')\n",
        "\n",
        "  y_train_list.append(data_labels[:800])\n",
        "  y_test_list.append(data_labels[800:])\n",
        "  clear_variable('data_labels')\n",
        "\n",
        "X_train = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable('X_train_list')\n",
        "\n",
        "X_test = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable('X_test_list')\n",
        "\n",
        "y_train = np.concatenate(y_train_list, axis=0)\n",
        "clear_variable('y_train_list')\n",
        "\n",
        "y_test = np.concatenate(y_test_list, axis=0)\n",
        "clear_variable('y_test_list')"
      ],
      "metadata": {
        "id": "0KBJbMt4EICa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = []\n",
        "X_test_list = []\n",
        "batch_size = 1000\n",
        "\n",
        "for start in range(0, len(X_train), batch_size):\n",
        "  X_train_batch = X_train[start : start + batch_size]\n",
        "  X_train_list.append(loaded_pca_64.transform(X_train_batch)) # Transform the X_train with PCA\n",
        "\n",
        "X_train_pca = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable(['X_train_list', 'X_train'])\n",
        "\n",
        "for start in range(0, len(X_test), batch_size):\n",
        "  X_test_batch = X_test[start : start + batch_size]\n",
        "  X_test_list.append(loaded_pca_64.transform(X_test_batch)) # Transform the X_test with PCA\n",
        "\n",
        "X_test_pca = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable(['X_test_list', 'X_test'])"
      ],
      "metadata": {
        "id": "Q0BaP3rYEN6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [800,1200,1800,2500,5000,7500,10000],\n",
        "              'gamma':[0.3,0.1,0.07,0.03,0.01,0.003]}\n",
        "\n",
        "grid = GridSearchCV(SVC(),\n",
        "                    param_grid,\n",
        "                    cv=5,\n",
        "                    verbose=3)\n",
        "\n",
        "grid.fit(X_train_pca, y_train)"
      ],
      "metadata": {
        "id": "LFyCDXMdhDmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = grid.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Best parameters: {x}'.format(x=grid.best_params_))\n",
        "print(\"Test Set Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "jRe3vHi5EXeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and format the classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "class_report_df = class_report_df.round(4)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_df.to_string())"
      ],
      "metadata": {
        "id": "8tkOq0t7EZBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA 128**"
      ],
      "metadata": {
        "id": "1vq4GgELEnMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list, X_test_list = [], []\n",
        "y_train_list, y_test_list = [], []\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_path = '/content/drive/MyDrive/ML_DL_Datasets/DNA_Datasets/Shuffled_Datasets/Covid_Shuffled_Balanced/Shuffled_Subset{file_counter}.h5'.format(file_counter = i+1)\n",
        "  read_data = pd.read_hdf(file_path) # Read the current dataset\n",
        "\n",
        "  data_reshaped = np.array(read_data.drop('Class', axis=1))\n",
        "  data_labels = read_data['Class']\n",
        "  clear_variable('read_data')\n",
        "\n",
        "  X_train_list.append(data_reshaped[:800])\n",
        "  X_test_list.append(data_reshaped[800:])\n",
        "  clear_variable('data_reshaped')\n",
        "\n",
        "  y_train_list.append(data_labels[:800])\n",
        "  y_test_list.append(data_labels[800:])\n",
        "  clear_variable('data_labels')\n",
        "\n",
        "X_train = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable('X_train_list')\n",
        "\n",
        "X_test = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable('X_test_list')\n",
        "\n",
        "y_train = np.concatenate(y_train_list, axis=0)\n",
        "clear_variable('y_train_list')\n",
        "\n",
        "y_test = np.concatenate(y_test_list, axis=0)\n",
        "clear_variable('y_test_list')"
      ],
      "metadata": {
        "id": "gN3BQgMnEr_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = []\n",
        "X_test_list = []\n",
        "batch_size = 1000\n",
        "\n",
        "for start in range(0, len(X_train), batch_size):\n",
        "  X_train_batch = X_train[start : start + batch_size]\n",
        "  X_train_list.append(loaded_pca_128.transform(X_train_batch)) # Transform the X_train with PCA\n",
        "\n",
        "X_train_pca = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable(['X_train_list', 'X_train'])\n",
        "\n",
        "for start in range(0, len(X_test), batch_size):\n",
        "  X_test_batch = X_test[start : start + batch_size]\n",
        "  X_test_list.append(loaded_pca_128.transform(X_test_batch)) # Transform the X_test with PCA\n",
        "\n",
        "X_test_pca = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable(['X_test_list', 'X_test'])"
      ],
      "metadata": {
        "id": "hQUg91SAEn0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [800,1200,1800,2500,5000,7500,10000],\n",
        "              'gamma':[0.3,0.1,0.07,0.03,0.01,0.003]}\n",
        "\n",
        "grid = GridSearchCV(SVC(),\n",
        "                    param_grid,\n",
        "                    cv=5,\n",
        "                    verbose=3)\n",
        "\n",
        "grid.fit(X_train_pca, y_train)"
      ],
      "metadata": {
        "id": "4m8PRpZsEwER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = grid.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Best parameters: {x}'.format(x=grid.best_params_))\n",
        "print(\"Test Set Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "bOo-R1wkE6YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and format the classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "class_report_df = class_report_df.round(4)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_df.to_string())"
      ],
      "metadata": {
        "id": "g2ka2WqDE7w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCA 256**"
      ],
      "metadata": {
        "id": "ribgNxKrE8YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list, X_test_list = [], []\n",
        "y_train_list, y_test_list = [], []\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_path = '/content/drive/MyDrive/ML_DL_Datasets/DNA_Datasets/Shuffled_Datasets/Covid_Shuffled_Balanced/Shuffled_Subset{file_counter}.h5'.format(file_counter = i+1)\n",
        "  read_data = pd.read_hdf(file_path) # Read the current dataset\n",
        "\n",
        "  data_reshaped = np.array(read_data.drop('Class', axis=1))\n",
        "  data_labels = read_data['Class']\n",
        "  clear_variable('read_data')\n",
        "\n",
        "  X_train_list.append(data_reshaped[:800])\n",
        "  X_test_list.append(data_reshaped[800:])\n",
        "  clear_variable('data_reshaped')\n",
        "\n",
        "  y_train_list.append(data_labels[:800])\n",
        "  y_test_list.append(data_labels[800:])\n",
        "  clear_variable('data_labels')\n",
        "\n",
        "X_train = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable('X_train_list')\n",
        "\n",
        "X_test = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable('X_test_list')\n",
        "\n",
        "y_train = np.concatenate(y_train_list, axis=0)\n",
        "clear_variable('y_train_list')\n",
        "\n",
        "y_test = np.concatenate(y_test_list, axis=0)\n",
        "clear_variable('y_test_list')"
      ],
      "metadata": {
        "id": "zN0p-30nFDf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = []\n",
        "X_test_list = []\n",
        "batch_size = 1000\n",
        "\n",
        "for start in range(0, len(X_train), batch_size):\n",
        "  X_train_batch = X_train[start : start + batch_size]\n",
        "  X_train_list.append(loaded_pca_256.transform(X_train_batch)) # Transform the X_train with PCA\n",
        "\n",
        "X_train_pca = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable(['X_train_list', 'X_train'])\n",
        "\n",
        "for start in range(0, len(X_test), batch_size):\n",
        "  X_test_batch = X_test[start : start + batch_size]\n",
        "  X_test_list.append(loaded_pca_256.transform(X_test_batch)) # Transform the X_test with PCA\n",
        "\n",
        "X_test_pca = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable(['X_test_list', 'X_test'])"
      ],
      "metadata": {
        "id": "tb1FN0ROE_Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [800,1200,1800,2500,5000,7500,10000],\n",
        "              'gamma':[0.3,0.1,0.07,0.03,0.01,0.003]}\n",
        "\n",
        "grid = GridSearchCV(SVC(),\n",
        "                    param_grid,\n",
        "                    cv=5,\n",
        "                    verbose=3)\n",
        "\n",
        "grid.fit(X_train_pca, y_train)"
      ],
      "metadata": {
        "id": "aNbrNgnjFFFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_estimator = grid.best_estimator_\n",
        "y_pred = best_estimator.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Best parameters: {x}'.format(x=grid.best_params_))\n",
        "print(\"Test Set Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "DcV-8FHZFFDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and format the classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "class_report_df = class_report_df.round(4)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_df.to_string())"
      ],
      "metadata": {
        "id": "I20dhJJLFHWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
