{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpBAJRJqnVopnw3QNnBGSU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEZm05s8Mh4G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import gc\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ntJplaAOMojI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd6d339-d2ec-4e97-d808-0e672cb68877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_variable(var_list):\n",
        "    for var in var_list:\n",
        "        globals().pop(var, None)  # Remove from global scope\n",
        "    gc.collect() # Run garbage collection"
      ],
      "metadata": {
        "id": "2qTU-_f1Mq5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []\n",
        "\n",
        "for i in range(20):\n",
        "  file_list.append(f'Shuffled_Subset{i+1}.h5')"
      ],
      "metadata": {
        "id": "m7KGnNFbMsk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list, X_test_list, X_val_list = [], [], []\n",
        "y_train_list, y_test_list, y_val_list = [], [], []\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_path = '/content/drive/MyDrive/ML_DL_Datasets/DNA_Datasets/Shuffled_Datasets/Covid_Shuffled_Balanced/Shuffled_Subset{file_counter}.h5'.format(file_counter = i+1)\n",
        "  read_data = pd.read_hdf(file_path) # Read the current dataset\n",
        "\n",
        "  data_reshaped = np.array(read_data.drop('Class', axis=1)).reshape(read_data.shape[0],30900,4)\n",
        "  data_labels = read_data['Class']\n",
        "  clear_variable('read_data')\n",
        "\n",
        "  X_train_list.append(data_reshaped[:700])\n",
        "  X_val_list.append(data_reshaped[700:800])\n",
        "  X_test_list.append(data_reshaped[800:])\n",
        "  clear_variable('data_reshaped')\n",
        "\n",
        "  y_train_list.append(data_labels[:700])\n",
        "  y_val_list.append(data_labels[700:800])\n",
        "  y_test_list.append(data_labels[800:])\n",
        "  clear_variable('data_labels')\n",
        "\n",
        "X_train = np.concatenate(X_train_list, axis=0)\n",
        "clear_variable('X_train_list')\n",
        "\n",
        "X_test = np.concatenate(X_test_list, axis=0)\n",
        "clear_variable('X_test_list')\n",
        "\n",
        "X_val = np.concatenate(X_val_list, axis=0)\n",
        "clear_variable('X_val_list')\n",
        "\n",
        "y_train = np.concatenate(y_train_list, axis=0)\n",
        "clear_variable('y_train_list')\n",
        "\n",
        "y_test = np.concatenate(y_test_list, axis=0)\n",
        "clear_variable('y_test_list')\n",
        "\n",
        "y_val = np.concatenate(y_val_list, axis=0)\n",
        "clear_variable('y_val_list')"
      ],
      "metadata": {
        "id": "MAPlzZtEMyWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Reshape input to 3D\n",
        "    model.add(layers.Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 1)))  # Adjusted pool size\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "'''"
      ],
      "metadata": {
        "id": "0ube4d-WNazC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**First Model**\n",
        "Three dense layers"
      ],
      "metadata": {
        "id": "0D69Hj0Fbf5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Reshape input to 3D\n",
        "    model.add(layers.Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 1)))  # Adjusted pool size\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(8, activation='relu'))\n",
        "#    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "o0QiaGLy86If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler callback\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 30 and epoch <= 40:\n",
        "        return 0.0001\n",
        "    elif epoch > 40:\n",
        "        return 0.00001\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (30900, 4)  # Shape of the input data: 30900 sequences, each with 4 features\n",
        "num_classes = 8  # Number of classes for classification\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_model = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "CLKa2qkXNf7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f50bfa17-1c8c-4e5a-d1db-c3d0275e1231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 30900, 4, 1)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 30900, 4, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15450, 2, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15450, 2, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7725, 1, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7725, 1, 128)      73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 3862, 1, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 494336)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               126550272 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126676944 (483.23 MB)\n",
            "Trainable params: 126676944 (483.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = cnn_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val), callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "qWyXARSTN7nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8685b5-739c-42e6-ff7b-624b27331a44",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 55s 355ms/step - loss: 1.9047 - accuracy: 0.3493 - val_loss: 1.0994 - val_accuracy: 0.6390 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 32s 296ms/step - loss: 0.9444 - accuracy: 0.6753 - val_loss: 0.6319 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.6632 - accuracy: 0.7580 - val_loss: 0.5335 - val_accuracy: 0.8050 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.5781 - accuracy: 0.7837 - val_loss: 0.4537 - val_accuracy: 0.8210 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.5247 - accuracy: 0.8019 - val_loss: 0.3996 - val_accuracy: 0.8460 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.4816 - accuracy: 0.8150 - val_loss: 0.3603 - val_accuracy: 0.8760 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.4509 - accuracy: 0.8251 - val_loss: 0.3099 - val_accuracy: 0.9150 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.4042 - accuracy: 0.8421 - val_loss: 0.2730 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.4029 - accuracy: 0.8426 - val_loss: 0.2859 - val_accuracy: 0.9160 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.3781 - accuracy: 0.8461 - val_loss: 0.2710 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.3621 - accuracy: 0.8516 - val_loss: 0.2507 - val_accuracy: 0.9170 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.3432 - accuracy: 0.8573 - val_loss: 0.2194 - val_accuracy: 0.9270 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.3570 - accuracy: 0.8549 - val_loss: 0.2105 - val_accuracy: 0.9220 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.3257 - accuracy: 0.8640 - val_loss: 0.2011 - val_accuracy: 0.9240 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.3046 - accuracy: 0.8683 - val_loss: 0.2079 - val_accuracy: 0.9270 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.2863 - accuracy: 0.8709 - val_loss: 0.1924 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 31s 284ms/step - loss: 0.2744 - accuracy: 0.8776 - val_loss: 0.1855 - val_accuracy: 0.9340 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.2521 - accuracy: 0.8884 - val_loss: 0.1913 - val_accuracy: 0.9070 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.2525 - accuracy: 0.8944 - val_loss: 0.1654 - val_accuracy: 0.9430 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.2309 - accuracy: 0.9043 - val_loss: 0.1626 - val_accuracy: 0.9460 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.2298 - accuracy: 0.9091 - val_loss: 0.1556 - val_accuracy: 0.9500 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 31s 284ms/step - loss: 0.2077 - accuracy: 0.9197 - val_loss: 0.1246 - val_accuracy: 0.9570 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.2052 - accuracy: 0.9239 - val_loss: 0.1173 - val_accuracy: 0.9670 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 31s 283ms/step - loss: 0.1857 - accuracy: 0.9329 - val_loss: 0.1046 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.1778 - accuracy: 0.9400 - val_loss: 0.1052 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.1673 - accuracy: 0.9409 - val_loss: 0.0913 - val_accuracy: 0.9780 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 31s 283ms/step - loss: 0.1549 - accuracy: 0.9470 - val_loss: 0.0905 - val_accuracy: 0.9820 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 31s 283ms/step - loss: 0.1392 - accuracy: 0.9516 - val_loss: 0.1135 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1402 - accuracy: 0.9516 - val_loss: 0.0759 - val_accuracy: 0.9820 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1320 - accuracy: 0.9560 - val_loss: 0.0917 - val_accuracy: 0.9810 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.1218 - accuracy: 0.9589 - val_loss: 0.0641 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1082 - accuracy: 0.9641 - val_loss: 0.0631 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1104 - accuracy: 0.9650 - val_loss: 0.0634 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1102 - accuracy: 0.9643 - val_loss: 0.0634 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1115 - accuracy: 0.9617 - val_loss: 0.0627 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.1102 - accuracy: 0.9626 - val_loss: 0.0630 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.0949 - accuracy: 0.9677 - val_loss: 0.0601 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.0985 - accuracy: 0.9670 - val_loss: 0.0625 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.1054 - accuracy: 0.9613 - val_loss: 0.0613 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.1035 - accuracy: 0.9660 - val_loss: 0.0607 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.1022 - accuracy: 0.9660 - val_loss: 0.0599 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.0876 - accuracy: 0.9689 - val_loss: 0.0594 - val_accuracy: 0.9850 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 31s 283ms/step - loss: 0.0938 - accuracy: 0.9706 - val_loss: 0.0588 - val_accuracy: 0.9850 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.1037 - accuracy: 0.9639 - val_loss: 0.0599 - val_accuracy: 0.9850 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.0990 - accuracy: 0.9649 - val_loss: 0.0605 - val_accuracy: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.0943 - accuracy: 0.9680 - val_loss: 0.0598 - val_accuracy: 0.9830 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 31s 285ms/step - loss: 0.1016 - accuracy: 0.9651 - val_loss: 0.0599 - val_accuracy: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 31s 282ms/step - loss: 0.0965 - accuracy: 0.9677 - val_loss: 0.0599 - val_accuracy: 0.9830 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.0920 - accuracy: 0.9670 - val_loss: 0.0596 - val_accuracy: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.1015 - accuracy: 0.9643 - val_loss: 0.0599 - val_accuracy: 0.9830 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "WhyaRIvdN-SV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedc30d4-9205-4359-a3a2-664f9862a453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 57ms/step - loss: 0.0696 - accuracy: 0.9801\n",
            "Test Loss: 0.0696132704615593\n",
            "Test Accuracy: 0.9800994992256165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to class labels\n",
        "predictions = cnn_model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, predicted_labels))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9zgjwQMcmVN",
        "outputId": "44ffce48-0a9c-4867-800e-968c82b7bb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 32ms/step\n",
            "[[328   1   0   0   0   0   0   1]\n",
            " [  0 416   0   0   0   0   4   0]\n",
            " [  0   0 360   0   0   0   0   0]\n",
            " [  0   2   0 358   0   0   0   0]\n",
            " [  1   0   0   0 136   0   3   0]\n",
            " [  0   0   0   0   0 160   0   0]\n",
            " [  1   7   0   0   0   0 140  12]\n",
            " [  0   5   0   0   0   0   3  72]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       330\n",
            "           1       0.97      0.99      0.98       420\n",
            "           2       1.00      1.00      1.00       360\n",
            "           3       1.00      0.99      1.00       360\n",
            "           4       1.00      0.97      0.99       140\n",
            "           5       1.00      1.00      1.00       160\n",
            "           6       0.93      0.88      0.90       160\n",
            "           7       0.85      0.90      0.87        80\n",
            "\n",
            "    accuracy                           0.98      2010\n",
            "   macro avg       0.97      0.97      0.97      2010\n",
            "weighted avg       0.98      0.98      0.98      2010\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.save('/content/drive/MyDrive/ML_Models/CNN_Model_Covid_(First_Model).h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzc-HvuccXkp",
        "outputId": "4ebf6810-9562-4378-bba3-d682ad622708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Second Model**\n",
        "Two dense layers"
      ],
      "metadata": {
        "id": "WUtYDmzbbMz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model_2(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Reshape input to 3D\n",
        "    model.add(layers.Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 1)))  # Adjusted pool size\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(8, activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "VwvTtMdkbG6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler callback\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 30 and epoch <= 40:\n",
        "        return 0.0001\n",
        "    elif epoch > 40:\n",
        "        return 0.00001\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (30900, 4)  # Shape of the input data: 30900 sequences, each with 4 features\n",
        "num_classes = 8  # Number of classes for classification\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_model_2 = create_cnn_model_2(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model_2.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn_model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yOiSAEhNb4iK",
        "outputId": "065c3e94-38e0-4745-c706-b3dd5e52942b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_1 (Reshape)         (None, 30900, 4, 1)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 30900, 4, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 15450, 2, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 15450, 2, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 7725, 1, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7725, 1, 128)      73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 3862, 1, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 494336)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               126550272 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126645072 (483.11 MB)\n",
            "Trainable params: 126645072 (483.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_2 = cnn_model_2.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val), callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2tdLCHfcCZx",
        "outputId": "1f7f3c5d-4cb7-4aa6-be76-158dd9b3ff9a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 36s 313ms/step - loss: 1.3716 - accuracy: 0.5694 - val_loss: 0.6925 - val_accuracy: 0.8060 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.6297 - accuracy: 0.8070 - val_loss: 0.4693 - val_accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.4678 - accuracy: 0.8529 - val_loss: 0.3670 - val_accuracy: 0.8990 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.3659 - accuracy: 0.8743 - val_loss: 0.2800 - val_accuracy: 0.9190 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 32s 292ms/step - loss: 0.3049 - accuracy: 0.8913 - val_loss: 0.2723 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.2625 - accuracy: 0.9026 - val_loss: 0.2141 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 32s 294ms/step - loss: 0.2159 - accuracy: 0.9250 - val_loss: 0.1996 - val_accuracy: 0.9410 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 32s 293ms/step - loss: 0.1752 - accuracy: 0.9470 - val_loss: 0.1548 - val_accuracy: 0.9450 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.1483 - accuracy: 0.9523 - val_loss: 0.1551 - val_accuracy: 0.9530 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.1360 - accuracy: 0.9524 - val_loss: 0.1388 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.1096 - accuracy: 0.9664 - val_loss: 0.1371 - val_accuracy: 0.9570 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.1033 - accuracy: 0.9673 - val_loss: 0.1183 - val_accuracy: 0.9660 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.0915 - accuracy: 0.9707 - val_loss: 0.1138 - val_accuracy: 0.9680 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0912 - accuracy: 0.9734 - val_loss: 0.1153 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.0755 - accuracy: 0.9774 - val_loss: 0.0972 - val_accuracy: 0.9690 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0599 - accuracy: 0.9807 - val_loss: 0.0910 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.0875 - val_accuracy: 0.9790 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.0491 - accuracy: 0.9841 - val_loss: 0.0799 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.0766 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 0.0650 - val_accuracy: 0.9830 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0616 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 0.0589 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.0561 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.0498 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0566 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.0513 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 0.0597 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0644 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0545 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0491 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0425 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 32s 289ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0420 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0422 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0444 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0431 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0425 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0439 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0449 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 32s 291ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0425 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 31s 286ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.0429 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0424 - val_accuracy: 0.9910 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0423 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0421 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0420 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0423 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0423 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 32s 287ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0426 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0426 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 32s 290ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0431 - val_accuracy: 0.9910 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 32s 288ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0434 - val_accuracy: 0.9910 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = cnn_model_2.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmQMUyX6e39i",
        "outputId": "e7ff37c1-ab8a-47b8-ce30-ab4612fad793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 31ms/step - loss: 0.0424 - accuracy: 0.9891\n",
            "Test Loss: 0.042395804077386856\n",
            "Test Accuracy: 0.9890547394752502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to class labels\n",
        "predictions = cnn_model_2.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, predicted_labels))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTBPIercfBMh",
        "outputId": "6d70a8fa-70f4-4d5b-ac28-c0d7737ac815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 30ms/step\n",
            "[[330   0   0   0   0   0   0   0]\n",
            " [  1 416   0   2   1   0   0   0]\n",
            " [  2   0 358   0   0   0   0   0]\n",
            " [  0   1   0 356   0   0   3   0]\n",
            " [  0   1   0   0 139   0   0   0]\n",
            " [  0   0   0   0   0 160   0   0]\n",
            " [  1   3   0   0   2   0 153   1]\n",
            " [  1   2   0   0   1   0   0  76]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       330\n",
            "           1       0.98      0.99      0.99       420\n",
            "           2       1.00      0.99      1.00       360\n",
            "           3       0.99      0.99      0.99       360\n",
            "           4       0.97      0.99      0.98       140\n",
            "           5       1.00      1.00      1.00       160\n",
            "           6       0.98      0.96      0.97       160\n",
            "           7       0.99      0.95      0.97        80\n",
            "\n",
            "    accuracy                           0.99      2010\n",
            "   macro avg       0.99      0.98      0.99      2010\n",
            "weighted avg       0.99      0.99      0.99      2010\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model_2.save('/content/drive/MyDrive/ML_Models/CNN_Model_Covid_(Second_Model).h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peGNiDn7fBr-",
        "outputId": "5a2e9086-5a1f-40c2-fb79-dbfc21c33155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMOxTnh2i1da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Model**\n"
      ],
      "metadata": {
        "id": "0iCr495FxdSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Reshape input to 3D\n",
        "    model.add(layers.Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 1)))  # Adjusted pool size\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(8, activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "POGRli1Bxq2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, data, labels, batch_size=32, shuffle=True):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_data = self.data[indices]\n",
        "        batch_labels = self.labels[indices]\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.data))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "tQLBoNEbxk2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler callback\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 30 and epoch <= 40:\n",
        "        return 0.0001\n",
        "    elif epoch > 40:\n",
        "        return 0.00001\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (30900, 4)  # Shape of the input data: 30900 sequences, each with 4 features\n",
        "num_classes = 8  # Number of classes for classification\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_model_3 = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model_3.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "cnn_model_3.summary()"
      ],
      "metadata": {
        "id": "gPrR8_0Dxsth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 64\n",
        "\n",
        "# Create data generators\n",
        "train_generator = DataGenerator(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "val_generator = DataGenerator(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
        "test_generator = DataGenerator(X_test, y_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "history_3 = cnn_model_3.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "z7LgSJbrxuvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = cnn_model_3.evaluate(test_generator)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "QOs2I8Qkxwj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using the model\n",
        "predictions = cnn_model_3.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since test_generator shuffles data, we need the original order for evaluation\n",
        "true_labels = np.concatenate([y_test[i*batch_size:(i+1)*batch_size] for i in range(len(y_test) // batch_size)])\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "print('\\n')\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "id": "0BwCCahnxyLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing Final Model**"
      ],
      "metadata": {
        "id": "D2UOwRCYx0KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.load_model('/content/drive/MyDrive/ML_Models/CNN_Model_Covid_(Balanced).h5')"
      ],
      "metadata": {
        "id": "lb09Mw6Cx5tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 64\n",
        "\n",
        "# Create data generators\n",
        "train_generator = DataGenerator(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "val_generator = DataGenerator(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
        "test_generator = DataGenerator(X_test, y_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "UOvgAIaC3qtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = cnn_model.evaluate(test_generator)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGhv8m2y8M7",
        "outputId": "1247fb1a-208d-4742-a1c7-d051025a9528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 11s 80ms/step - loss: 0.0493 - accuracy: 0.9932\n",
            "Test Loss: 0.0493064783513546\n",
            "Test Accuracy: 0.9931955933570862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using the model\n",
        "predictions = cnn_model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since test_generator shuffles data, we need the original order for evaluation\n",
        "true_labels = np.concatenate([y_test[i*batch_size:(i+1)*batch_size] for i in range(len(y_test) // batch_size)])\n",
        "\n",
        "# Compute and format the classification report\n",
        "class_report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
        "class_report_df = pd.DataFrame(class_report).transpose()\n",
        "class_report_df = class_report_df.round(4)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(class_report_df.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpHkc5lUZVMd",
        "outputId": "78642b76-2f35-4799-83bd-7bce05137946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 3s 55ms/step\n",
            "Classification Report:\n",
            "              precision  recall  f1-score    support\n",
            "0                0.9958  1.0000    0.9979   474.0000\n",
            "1                0.9888  0.9833    0.9860   359.0000\n",
            "2                1.0000  0.9966    0.9983   597.0000\n",
            "3                0.9940  0.9940    0.9940   497.0000\n",
            "4                0.9982  0.9928    0.9955   554.0000\n",
            "5                0.9960  0.9960    0.9960   497.0000\n",
            "6                0.9842  0.9977    0.9909   436.0000\n",
            "7                0.9855  0.9838    0.9846   554.0000\n",
            "accuracy         0.9932  0.9932    0.9932     0.9932\n",
            "macro avg        0.9928  0.9930    0.9929  3968.0000\n",
            "weighted avg     0.9932  0.9932    0.9932  3968.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using the model\n",
        "predictions = cnn_model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Since test_generator shuffles data, we need the original order for evaluation\n",
        "true_labels = np.concatenate([y_test[i*batch_size:(i+1)*batch_size] for i in range(len(y_test) // batch_size)])\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "print('\\n')\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek45E5HM2gd-",
        "outputId": "6797407e-2995-48b3-f6c4-b5f500dc138e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 365s 6s/step\n",
            "[[474   0   0   0   0   0   0   0]\n",
            " [  0 353   0   0   1   0   0   5]\n",
            " [  0   0 595   0   0   1   0   1]\n",
            " [  0   0   0 494   0   1   2   0]\n",
            " [  0   0   0   1 550   0   2   1]\n",
            " [  2   0   0   0   0 495   0   0]\n",
            " [  0   0   0   0   0   0 435   1]\n",
            " [  0   4   0   2   0   0   3 545]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       474\n",
            "           1       0.99      0.98      0.99       359\n",
            "           2       1.00      1.00      1.00       597\n",
            "           3       0.99      0.99      0.99       497\n",
            "           4       1.00      0.99      1.00       554\n",
            "           5       1.00      1.00      1.00       497\n",
            "           6       0.98      1.00      0.99       436\n",
            "           7       0.99      0.98      0.98       554\n",
            "\n",
            "    accuracy                           0.99      3968\n",
            "   macro avg       0.99      0.99      0.99      3968\n",
            "weighted avg       0.99      0.99      0.99      3968\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puQCdLYx2o_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}